{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfB14Tna2sgteE7pmCU9K7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TeddyDo1999/DREXEL-DISCO-RISC-V-Simulator-C-Impl/blob/master/MNISTclf_classic_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XK_xod36pjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc965e3-7863-4a81-bb75-c19f2ebfd03a"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1bGy-TLnWb_8Ad1A4G41hVZiZgtdZl_yV\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('mnist_X_train1.pkl')\n",
        "\n",
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Jan  6 10:06:56 2021\n",
        "\n",
        "@author: Hanh Do Phung\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#%%\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "\n",
        "X = pd.read_pickle(\"mnist_X_train1.pkl\")\n",
        "y = pd.read_pickle(\"mnist_y_train.pkl\")\n",
        "\n",
        "import pickle\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "#Data preprocessing\n",
        "pca3 = PCA(n_components=0.3)\n",
        "steps_transform = [\n",
        "        ('pca', pca3),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "        ]\n",
        "\n",
        "transform_pl = Pipeline(steps_transform)\n",
        "\n",
        "X_pca3 = transform_pl.fit_transform(X)\n",
        "\n",
        "\n",
        "#KNN\n",
        "knn_clf = KNeighborsClassifier(weights='distance', n_neighbors=4)\n",
        "predict_score = cross_val_score(knn_clf, X_pca3, y, cv=3, scoring=\"accuracy\")\n",
        "print(predict_score)\n",
        "knn_clf.fit(X_pca3, y)\n",
        "\n",
        "DATA_PATH = '/content'\n",
        "filename_pipe = DATA_PATH+'/knn_dist_4_pc3.pkl'\n",
        "pickle.dump(knn_clf, open(filename_pipe, 'wb'))\n",
        "\n",
        "\n",
        "#Logreg\n",
        "logreg_clf = LogisticRegression(\n",
        "                  multi_class=\"multinomial\",\n",
        "                  solver=\"lbfgs\", C=0.01, random_state=42, max_iter=60000, class_weight=\"balanced\")\n",
        "predict_score = cross_val_score(logreg_clf, X_pca3, y, cv=3, scoring=\"accuracy\")\n",
        "print(predict_score)\n",
        "logreg_clf.fit(X_pca3, y)\n",
        "\n",
        "DATA_PATH = '/content'\n",
        "filename_pipe = DATA_PATH+'/logreg_C001_pc3.pkl'\n",
        "pickle.dump(knn_clf, open(filename_pipe, 'wb'))\n",
        "\n",
        "#svm\n",
        "non_lin_svm_clf = SVC(kernel=\"poly\", degree=4, C=5)\n",
        "predict_score = cross_val_score(non_lin_svm_clf, X_pca3, y, cv=4, scoring=\"accuracy\")\n",
        "print(predict_score)\n",
        "non_lin_svm_clf.fit(X_pca3, y)\n",
        "\n",
        "DATA_PATH = '/content'\n",
        "filename_pipe = DATA_PATH+'/svm_deg4_C5.pkl'\n",
        "pickle.dump(knn_clf, open(filename_pipe, 'wb'))\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(‘knn’, knn_clf), (‘svm’, non_lin_svm_clf), (‘log_reg’, logreg_clf)]\n",
        "#create our voting classifier, inputting our models\n",
        "ensemble = VotingClassifier(estimators, voting=’hard’)\n",
        "ensemble.fit(X_pca3, y)\n",
        "\n",
        "print(ensemble1.score(X_pca3[810:1810], y[810:1810]))\n",
        "\n",
        "DATA_PATH = '/content'\n",
        "filename_pipe = DATA_PATH+'/ensemble_clf.pkl'\n",
        "pickle.dump(ensemble1, open(filename_pipe, 'wb'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'log_reg__C': 0.01, 'pca__n_components': 0.5}\n",
            "1.3053735097664576\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}